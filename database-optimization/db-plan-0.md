Proposed Database Schema for Fashion-Fit App

This schema integrates and refines the structures from the Freestyle DB and Tailor3 SQL dumps into a unified design. It supports the app’s three phases – LOGGER (try-on logging), SIES (size/measurement inference), and PROXI (proxy try-on via size twins) – with strong relational integrity and scalability in mind. We use normalized tables with clear foreign keys, ensure indexes on key columns, and anticipate future social features.

Core Entities: Users, Brands, and Products

Users / Profiles – Use Supabase’s auth.users for authentication (UUID primary keys), with a separate profiles table for app-specific info (display name, avatar, etc.). The profiles.user_id is a UUID FK to auth.users, ensuring one-to-one relation and easy join on user data. This keeps auth secure while allowing profile updates. Millions of users are supported by using UUIDs and indexing profiles(user_id) for quick lookups.
Future: A user_preferences field (or table) can store settings like preferred measurement unit (as seen in Tailor’s unused user_preferences.preferred_unit).

Brands – A brands table stores each clothing brand (millions of products across thousands of brands). Basic fields: id (bigserial PK), name (text), website (URL), region (optional). Use a unique index on name+region to prevent duplicates. A default_unit (e.g. "in" or "cm") can be stored for that brand’s sizing. For relational integrity, this id is referenced by products, size guides, etc.
Extension: A brand_profile table (1-1 with brand) can hold extra data and rules. For example, Freestyle had a brand_profile with a JSON rules field to capture brand-specific sizing quirks or conversion notes (e.g. “Brand runs small”). This could store measurement adjustment rules or parsing instructions, and notes_md for internal notes.

Categories & Subcategories – A hierarchical category taxonomy classifies garments (e.g. Shirts, Pants, with subcategories like Dress Shirts, Jeans). A categories table holds top-level or generic categories (id, name, parent_id for hierarchy). A separate subcategories table can refine these further (or use self-referencing in categories). Tailor3 used a subcategories table linking to category_id. We ensure a foreign key subcategories.category_id → categories.id. This normalization avoids inconsistent naming across brands.
Brand Mapping: To handle brand-specific category labels, a mapping table (e.g. brand_category_map) links a brand’s original category label to our standardized category. This helps when ingesting product data from different brands and ensures consistent category assignment.

Products and Variants – We model garments in two levels: Product (Style) and Product Variant. This follows the improved Tailor3 design where the legacy single garments table was replaced by a master/variant structure for better normalization.

Products – Stored in products (or product_master) table, each represents a base style or item across variants. Fields: id (bigserial PK), brand_id (FK to brands), category_id and optional subcategory_id (FKs to categories), product_code (brand’s style code or SKU root), name (descriptive name), and descriptive attributes like description, gender (enum or text), etc. We include timestamps (created_at, updated_at) for auditing. The combination of brand and product_code can be indexed unique to prevent duplicates. A product record aggregates common info (material, care instructions, etc. – which we can store as JSON or separate fields). Normalizing product info avoids duplicating descriptions for each variant.

Variants – Stored in product_variants table, representing a specific option of a product (e.g. a particular color and fit). Fields: id (bigserial PK), product_id (FK to products), variant_code or SKU (unique to this variant), color_name (text) and optional color_code or hex value, fit_option (text, e.g. “Regular” or “Slim”), plus availability data like current_price, currency, in_stock, etc. Each variant can also list sizes_available (all size labels offered) and which are sizes_in_stock. We store last_checked timestamp for inventory updates. Foreign keys ensure each variant links to a valid product and brand. Index product_variants.product_id for quick retrieval of all variants of a style.

Product Codes – If needed, a product_codes table can store alternate identifiers (e.g. multiple SKUs or regional codes) with fields for code type and region, but we can also incorporate a region field in variant or product code if a simple case. This ensures one product can have multiple market-specific identifiers without duplicating the product entry.

Product Media – The schema supports storing product images. We use a product_images table to store image records for products/variants, rather than an array, for easier querying and CDN integration. Fields: id PK, product_id or variant_id (FK), url (or storage path) to the image, position (int ordering), and a boolean is_primary to flag the main image. This design (seen in Freestyle’s product_images table) allows multiple images per variant (different angles, colors) with one marked primary. We also store dimensions or thumbnail info (width/height) if needed. Index on (variant_id, is_primary) can help fetch the primary image quickly for product listings.

Relational Integrity: All product-related tables use foreign keys (brand_id in products, product_id in variants/images) to maintain referential integrity – e.g., deleting a brand could cascade to its products (or we restrict deletion if product records exist). We also ensure consistency between product and variant attributes (e.g., variant.color_name might map to a global color list if needed via a colors table, but we can also enforce consistency by mapping brand color names to canonical colors using a map table as Freestyle did). For performance with millions of products/variants, we rely on indexing PKs and foreign keys; partitioning by brand or category can be considered if tables grow extremely large.

Size Guides and Measurement Data (SIES Phase)

To enable the SIES phase – using known size guides to infer user body measurements and suggest sizes – we incorporate a robust measurement schema inspired by Tailor3’s approach. Rather than storing static size chart fields, we use a flexible measurement set model that can handle various garment dimensions and units:

SizeGuide / MeasurementSet – A measurement_sets table represents a set of measurements, typically a size chart for a brand/category or a specific garment’s spec sheet. Key fields: id (bigserial PK), brand_id (FK), category_id (FK), gender (e.g. Male/Female, if the brand has gendered sizing), and fit_type (e.g. Regular, Tall – if the brand has separate fit-specific charts). We include scope to distinguish size guides (body measurements per size) vs garment specs (actual garment measurements). For example, a size guide for shirts might have scope 'size_guide' and no specific garment, whereas a particular style’s measured dimensions might be scope 'garment_spec' with a garment_id or product_id reference. Each measurement set also stores metadata: source (e.g. "Manufacturer site"), source_url, and timestamps. A boolean is_active indicates the current valid guide if multiple versions exist. By separating this table, we prepare for thousands of size charts – each brand can have multiple charts (e.g. for different clothing categories or revisions), indexed by brand for quick lookup. (Tailor3 similarly replaced their old size_guides table with measurement_sets for flexibility.)

Measurements – The actual measurement entries (e.g. “Chest: 38-40 inches for size M”) are stored in a measurements table. Each row is a specific measurement for a given size label within a measurement set. Key fields: id (PK), set_id (FK to measurement_sets), size_label (text, e.g. "S", "M", "L"), measurement_type (text code for the dimension, e.g. chest, waist, sleeve), and numeric values. We accommodate ranges or exact values: for body measurements, brands often give a range (min–max) that the size fits (e.g. chest 38–40"); for garment specs, it might be an exact value (e.g. shirt chest width = 21"). Accordingly, we have min_value and max_value columns, and an exact_value if applicable. A generated column midpoint_value can compute the average when only a range is given, and a range_text can store a human-friendly "X-Y" or single value. We also store unit (usually "in" or "cm") and possibly a unit_conversion_factor to convert values if needed. Each measurement row is tagged with a source_type indicating whether it came from an official size guide, a garment spec, user measured data, etc. (e.g. 'size_guide', 'garment_spec'). This approach is highly normalized and extensible – adding a new measurement dimension (e.g. hip circumference) doesn’t require new table columns, just new rows with measurement_type='hip'. We ensure data integrity with check constraints or an enum on measurement_type (e.g. only allow known dimension codes like chest, waist, neck, sleeve, etc). Tailor’s design uses a similar mechanism, storing one row per measurement and even computing midpoint and text automatically. We follow this to support any number of measurements per size. Indexing (set_id, size_label) helps retrieve all measurements for a given size or an entire size chart quickly.

Example: A size guide (measurement_set) for Brand X Men’s Shirts might have rows in measurements like: size "M" – body_chest min 38, max 40; body_neck min 15, max 15.5; body_sleeve min 33, max 34, etc., all tied by the same set_id. Another measurement_set for Brand X Shirt #123 garment_spec could have exact garment_chest_width = 20" for size M, etc., with scope 'garment_spec'.

Linking to Products – The products table can have an optional measurement_set_id to directly reference a garment’s specific measurement table if one exists (for example, if we have exact factory measurements for that style). In general, however, a product will link to a brand and category, and from those we determine which size guide to use. For instance, if a user logs a shirt from Brand X, we find Brand X’s active shirt size guide (where brand_id = X and category = Shirt in measurement_sets). We ensure brand + category + gender + fit yields at most one active guide for unambiguous lookup (enforced via unique index or a separate guide_selection_rules if needed). This way, even as brands number in the thousands, each product can quickly find the relevant size chart.

Measurement Types – We maintain a reference list of standard measurement dimension codes (e.g. a measurement_types table or enum: “chest”, “waist”, “sleeve”, etc). This can store human-friendly names and categorize them as body vs garment measurements. (Tailor’s schema included a measurement_types table listing codes and categories). Using consistent measurement codes across brands enables the SIES logic to compare user data to any brand’s size chart.

Brand-specific Mapping – Because brands use different terms (e.g. "Sweep" vs "Hem Width" for waist, or different units), we include tables to map and standardize these:

measurement_mappings: maps a brand’s measurement term to our standard measurement_type (e.g. Brand Y’s "Natural Waist" -> waist).

measurement_instructions: if needed, stores how a brand measures a dimension (text instructions), since one brand’s "sleeve" might measure from center back versus another from shoulder seam. This can be stored as a text or JSON in brand_profile or a dedicated table (Tailor used brand_measurement_instructions). These mappings and instructions ensure that when we parse size guide data or compare across brands, we’re aligning equivalent measurements.

Using these tables, the SIES engine can reverse-engineer a user’s body measurements. For example, if a user typically wears Size M in Brand X Shirts, we find Brand X’s shirt size guide, take the chest range for M (say 38–40"), and infer the user’s chest is ~39" (midpoint) or at least within that range. By aggregating multiple such data points across brands/categories, we can populate a UserBodyMeasurements profile.

User Body Measurements – We add a user_body_measurements table (one per user, or a versioned history) to store the inferred physical measurements of the user (chest, waist, etc). This is essentially the output of SIES for each user. Tailor3 planned a similar body_measurements table (though marked unused) for chest, waist, neck, etc. Our design would update this table whenever new fit data refines the estimates. Fields: user_id (FK), each major measurement (numeric, probably in inches by default), a confidence_score or accuracy rating for each (could be in a JSON or separate fields), and timestamps. Having this table precomputed can speed up finding size twins in PROXI, since we can compare users by these numeric measures rather than on-the-fly inference each time. However, it’s optional – these values could also be derived dynamically by querying the user’s fit logs against size guides. Storing them is a practical denormalization for performance, given millions of users (we would index by each measurement or use a vector index if doing range queries for similarity).

User Fit Logging (LOGGER Phase)

The LOGGER phase is handled by tables that record each instance of a user trying on or owning a garment, along with the fit feedback. We combine the structures of Freestyle’s user_closet/fit_feedback with Tailor’s more granular user_garments and feedback codes to create a comprehensive logging system:

UserGarments (Fit Log) – This central table (could be named user_garments or user_fits) records every garment a user logs, whether just tried on or actually owned. Each entry captures: id (bigserial PK), user_id (UUID FK to users), product_id and variant_id (FKs to the product/variant tried), size_label (text, the size the user tried or purchased), and context fields like input_method (how the item was logged: via link, scan, etc) and link_provided (the URL if they entered one). We also include a status or garment_status to indicate the outcome: e.g. "owned" (purchased/kept), "tried" (tried but not purchased), "returned", etc. (Tailor introduced an enum garment_status with default "owned" to represent this). A boolean owns_garment can mirror this status (true if they kept it) for quick filtering. We store created_at and updated_at timestamps. There’s also a notes text for any user-written comments on the fit or style.

Relationships: user_garments.user_id → profiles.user_id; product_id/variant_id → products/variants. These FKs ensure logs refer to valid catalog items and users. If a product or variant isn’t recognized in our catalog (e.g. a new URL the system hasn’t parsed yet), we can allow variant_id to be NULL initially and later fill it once the ingest parses the product (or use a placeholder “unparsed product” entry).

Indexing: We will index user_garments(user_id) to retrieve a user’s closet history efficiently (e.g. “My Closet” feature or analytics). We’ll also index (variant_id, size_label) since PROXI queries will look up “who else has this same variant and size”. For scale, note that if millions of users each log many items, this table could grow to tens of millions of rows; indexing and possibly partitioning by variant_id or user_id might be considered down the line for performance.

Fit Feedback (Detailed) – Instead of a single “fit score”, we capture detailed feedback per logged item using a user_garment_feedback table. Each feedback entry is linked to a user_garment record via user_garment_id (FK). We include: dimension (text enum: e.g. "overall", "chest", "waist", "sleeve", "length", etc.), and a feedback_code_id (FK to a feedback_codes table) representing the user’s input. For example, for dimension "chest" the user might select “Too Tight”, which corresponds to a standardized code. Tailor’s schema used feedback_codes to represent phrases and type (fit vs length) – e.g. a code might have feedback_text = "Too Loose" and feedback_type = "fit" indicating a fit issue. The use of codes ensures consistency (all users use the same terms) and easy analysis (counting how often "Too short sleeves" appears, etc.). We include a timestamp and possibly the measurement_source context if needed (Tailor tracked whether feedback was relative to a size guide or garment spec measurement), though in our app’s UI it might be abstracted away. A check constraint enforces valid dimension values.

Each user_garment could have multiple feedback entries (covering different dimensions). We also allow an "overall" feedback as one of the dimensions – e.g. an overall rating like “True to size” or “Size up recommended”, which would be a code under dimension "overall". This covers general fit satisfaction. Additionally, the user_garments table itself has a size_label (the size worn) and could have a quick overall fit flag (like fit_feedback_summary) but we mostly rely on detailed feedback entries for richness. If needed, we could store an aggregate like a numeric fit score (e.g. 0 = too small, 1 = perfect, 2 = too large) in user_garments for simple queries, but the codes make that largely unnecessary. Freestyle’s simpler design logged one fit_feedback.fit_result per trial (likely an integer or enum) and a notes field. Our approach generalizes this: we can interpret an “overall too small” as a feedback entry on overall fit, and still capture specific areas (chest tight, sleeves short, etc.).

Feedback Codes: We maintain a feedback_codes reference table containing all possible feedback options (e.g. "Too Tight", "Too Loose", "Too Short", "Perfect Fit", etc.) with attributes: id, feedback_text, feedback_type (categorizing it as a fit issue vs length issue vs other), and possibly an is_positive flag for whether it's good or bad feedback. This table is small (handful of entries) but ensures normalization (no typos or phrasing differences). We may pre-populate it with common responses. The feedback_code_dimensions link table from Tailor suggests some codes could apply to multiple dimensions (though typically "Too Tight" can apply to chest or waist, etc.). We could simplify by having distinct codes per dimension category (like "Too tight in body" vs "Too tight in neck" if needed), or use that link table if reusability is desired. For now, we can assume codes are written general enough or dimension-specific as needed.

Example: A user logs a Medium for a shirt and indicates it’s slightly tight in the chest and perfect elsewhere. We’d have user_garments entry (user=X, variant=Shirt123-Medium, status="tried") and two user_garment_feedback entries: one with dimension="chest", feedback_code="Too Tight", and one with dimension="overall", feedback_code="Fit Okay" (or perhaps no overall if the system doesn’t require it). If the user ended up buying a Large instead, there’d be another user_garments entry for Large marked owned and likely with feedback indicating a good fit.

UserGarment Media (Photos/Videos) – To support image uploads (outfit photos, tag photos, etc.), we have a user_garment_photos (or user_media) table. Each entry: id (PK), user_garment_id (FK to the log entry it illustrates), photo_url (or path to the stored media), and photo_type (enum: e.g. "tag" for a clothing label/tag photo, "fit" for a try-on photo from camera, "gallery" if uploaded from gallery). We also include caption (user’s caption or notes about the photo) and a metadata JSON (could store things like orientation or detected info). A boolean is_primary marks if this photo should represent the log entry in feeds (e.g. if multiple photos, the front-view outfit photo might be primary). We include timestamps for when uploaded. This design is drawn from Tailor’s user_garment_photos setup. By having a separate table, users can upload multiple images per try-on. In the future, we can extend this to videos by either adding a media_type field (image vs video) or a separate but similar table for videos. For now, images and videos can be handled in one table by storing a URL and maybe a type or file extension indicator. All media entries link back to the user_garments record, and we might also store the user_id redundantly for easy filtering (with FK or trigger to ensure consistency). Supabase storage can be used to actually host the files, and photo_url would point to that. We do not store large binary in the database; just references, for scalability.

Logging Workflow Integration: When a user enters a product URL in LOGGER phase, the system creates a user_garments record (possibly as a placeholder while the product details are fetched). The ingestion pipeline will parse the URL to identify brand, style, and available sizes. We likely store the raw URL in user_garments.link_provided and create an ingestion_task to fetch product data (Freestyle had tables like ingestion_job and ingestion_task to track scraping tasks). Those are implementation details outside the core schema answer, but our schema can accommodate incomplete data (e.g. if variant_id is null initially, we update it once the product is in our catalog). The user is then prompted to enter what size they tried; we update user_garments.size_label and then prompt the fit questions, resulting in user_garment_feedback entries and perhaps a photo upload. This all links back to the catalog and size guide data, enabling the SIES calculations.

Proxy Try-On & Social Features (PROXI Phase and Beyond)

The PROXI phase encourages users to find “size twins” – other users with a similar fit – and to view those users’ garment logs as a guide for what might fit. Our schema enables this through relational queries and is extensible to general social networking features:

Finding Size Twins: We can determine similarity either by exact overlaps or by measurements. In the simplest case, we find users who logged the same variant and same size. For example, if user A and user B both own the Brand X Shirt, size M, they likely have similar body size. Freestyle’s v_proxy_feed view implemented this logic by self-joining the user-owned items table on matching variant_id and size_label where user IDs differ. We would replicate such a query: join user_garments as UG1 and UG2 on UG1.variant_id = UG2.variant_id AND UG1.size_label = UG2.size_label AND UG1.user_id <> UG2.user_id, and perhaps filter to only include items with status='owned' (to find genuine kept items). This yields pairs of users who share an item/size. A materialized view or indexed query can provide quick lookup: given a user, find all variant_id they own, then find other owners of those variants.

However, to go beyond exact item matches (since two users might be size twins even if they haven’t tried the exact same product), we leverage the UserBodyMeasurements profile. We can perform a nearest-neighbor search on the continuous attributes (chest, waist, etc.) to find users with measurements within a small delta. For example, find users whose inferred chest is within 1 inch and waist within 1 inch of the target user. This could be done via direct SQL (range conditions on those columns) or using extensions (Postgres cube/earthdistance or vector similarity if we treat measurements as vectors). As an approximation, we could categorize users into size zones (like Tailor’s fit_zones table attempted to do) based on general size (small/medium/large categories for key measurements), and then match users in the same zone. The schema supports either approach: the user_body_measurements table provides the data needed for numeric comparison, and we can add indexes or materialized views for performance. For instance, we might add a generated column with a tsvector of size descriptors or use a B-Tree index on each measurement field.

Viewing Others’ Logs (Proxy Try-On): Once a user finds a potential twin, they should be able to browse that person’s garment logs. Thanks to our schema, this is straightforward: just query user_garments for the twin’s user_id. We can create a feed of items for the user to explore. Freestyle’s v_proxy_feed view assembled a sentence like “User2 also owns Brand X Style Y (size M)” as a feed item, pulling product name, images, and price. We can similarly create a view or query that selects, for a given user (viewer), the set of user_garments from others that match on size/variant or are from similarly sized users. This view could join across: user_garments UG2 of potential twins, the products and brands to get names, and the product_images to get a photo. We might exclude items the viewer already owns. The result is that the user can virtually “try on” those items by proxy – if someone with their measurements fit into a garment, it’s likely to fit the user as well.

We preserve privacy and control with such features – possibly only surface data from users who opt-in or are followed.

Social Network Tables: To support future social features like following, liking, messaging, and saving outfits, we design a few additional tables:

Follows: A user_follows table (or relationships) with follower_id and followee_id (both FKs to users), plus a timestamp. This allows users to follow others’ updates. We index on follower_id (to get whom I follow) and on followee_id (to get follower count or list). This table can easily scale to millions of entries (assuming at most tens or hundreds per user on average, still manageable).

Likes & Favorites: Users might “like” another user’s outfit log or save it for reference. We can implement a user_likes table that is polymorphic – containing user_id, content_type, content_id, with content types like 'garment_log' or 'outfit'. Simpler, we can have separate tables if needed: e.g. user_garment_likes (user_id, user_garment_id) to like try-on posts, and user_outfit_likes similarly. A user_saved_items or user_favorites table could track items a user saved for later (like bookmarking an outfit or product). This is essentially the “saving outfits” feature. If we introduce a distinct Outfit entity (where a user can combine multiple pieces into a styled outfit post), we’d have an outfits table (with its own id, owner user_id, description) and an outfit_items join table linking outfits to the constituent user_garments or direct product references. Then saving an outfit is just following or liking that outfit record. In the absence of an explicit outfit entity, “saving outfit” might mean saving another user’s user_garment entry (if each entry is considered a shared outfit look). Our schema can evolve to add an outfits table when needed without affecting existing tables.

Messaging: A basic messaging table user_messages with id, sender_id, receiver_id (FKs to users), body text, sent_at timestamp can enable direct user-to-user messages or comments. For extensibility, one could also have a thread_id for conversations, but a simple approach is fine initially. This does not directly interact with the fit data tables, so it can be added with minimal impact.

All these social tables use foreign keys to the main users/profiles table for referential integrity. They can be extended with cascade delete or soft-delete as needed (for example, if a user deletes their account, we might choose to remove their follows, likes, etc., or anonymize them). Indices on these tables (e.g. on user_likes.user_id and content_id) ensure lookups remain fast even as the user base grows.

Performance and Scaling Considerations

This schema is designed for PostgreSQL (Supabase) and thus leverages its features (FK constraints, check constraints, views, etc.) while preparing for high scale:

Primary Keys & Indexing: All tables have primary keys (mostly integer/bigint sequences or UUID for user-related tables). Foreign keys are indexed by default or explicitly to optimize joins. We will add additional indexes on query-critical fields: e.g., user_garments(user_id) and user_garments(variant_id, size_label) as noted, product_variants(product_id), measurements(set_id, size_label, measurement_type), etc. These ensure that even with millions of rows, lookups and joins use index scans. We also consider composite indexes for common query patterns (for instance, an index on user_garments(user_id, status) if we frequently query a user’s owned items vs tried items separately).

Normalization vs Denormalization: We normalized entities (users, brands, products, measurements) to avoid data duplication and update anomalies – this is crucial for integrity given the scale (e.g., one canonical brand name entry, one product record per style). However, we carefully denormalize where it improves performance without data integrity loss. For example, storing midpoint_value and range_text in measurements is a form of denormalization (deriving from min/max) that accelerates queries and simplifies usage. Similarly, caching a user’s body measurement summary in user_body_measurements is denormalization of the underlying fit data – we maintain it via app logic to avoid heavy recomputation for each query. We also use materialized views for expensive aggregations if needed (as Tailor did with fit_measurements materialized view to flatten measurement data for analysis). For example, we could create a materialized view that joins users with their most likely size in each brand, which SIES computes, to quickly answer “what size would user X be in brand Y?”.

Partitioning and Sharding: In PostgreSQL, if some tables grow extremely large (hundreds of millions of rows), we can employ partitioning. For instance, user_garments could be range-partitioned by created_at (by year or month) or hash-partitioned by user_id to distribute writes and keep indexes smaller per partition. This isn’t initially necessary, but the schema doesn’t prevent it – we could declaratively partition when needed because foreign keys can now reference partitions (as of PG 15). Likewise, read-heavy tables like measurements might be partitioned by brand_id if each brand’s size data is often accessed together. In a Supabase environment, scaling up (or out with read replicas) can handle a lot before partitioning is required, but we mention it as a future scaling tactic.

Supabase Considerations: Supabase being backed by Postgres means all our design (FKs, constraints, etc.) is supported. We also integrate with Supabase Auth (users) and Storage (for media). For example, instead of raw URLs, user_garment_photos.photo_url might be a path that, when combined with a Supabase storage bucket URL, yields the actual link. We ensure our schema stores just references, not the files themselves. We can also leverage Supabase Real-time or Row-Level Security policies later for the social features (ensuring, say, that users only see other users’ data if permitted). These are beyond schema definition but our design (with clear user FKs) makes implementing security policies straightforward (e.g. policy on user_garments that user can select only their own or those of followed users if we restrict).

Foreign Key Cascades: We carefully choose FK on-delete behaviors to maintain integrity. For example, if a product is deleted from the catalog (perhaps a rare admin action), we might want to also remove or orphan related user logs. Instead, likely we’ll mark products as discontinued (a boolean) rather than delete, to preserve user history. Similarly, if a user deletes their account, we might anonymize their logs rather than delete them (for analytics value). In schema terms, we’d set ON DELETE SET NULL or have a separate process, rather than blindly cascading deletes. Our relational design makes it possible to cascade if needed (because of FK constraints), but domain logic will dictate the right approach.

Extensibility: Adding new features should not require big schema changes. For instance, if we later add Outfits as a first-class entity, we’d create new tables (outfits, outfit_items) that reference existing user_garments or product_variants. This doesn’t disturb existing tables. If a new measurement dimension becomes relevant (say, thigh circumference for pants), we just add a new entry to measurement_types and start inserting it into measurements – no alteration of table structure needed. The use of JSONB for some fields (e.g. products.materials or product_variants.images if we choose, or user_garment_photos.metadata) provides flexibility for rarely queried attributes without performance impact on core queries. We avoid overusing JSON for frequently needed data to keep things indexable and relational.

Example Relationship Summary (ERD Notes): To clarify table linkages, here are key relationships:

Brand 1–* Product – one brand has many products (products.brand_id FK).

Category 1–* Product – one category maps to many products (products.category_id FK), with subcategory similarly.

Product 1–* Variant – one product has many variants (product_variants.product_id FK).

Product/Variant 1–* ProductImage – one product or variant can have multiple images (product_images.variant_id FK, optionally product_id).

Brand/Category 1–* MeasurementSet – a brand-category (and gender/fit combination) can have multiple measurement sets over time (measurement_sets.brand_id, category_id FKs). Only one is active per category/gender/fit at a time.

MeasurementSet 1–* Measurement – one size guide or spec sheet has many measurements entries (measurements.set_id FK) – each for a specific size & dimension.

User 1–* UserGarment – each user can log many garments (user_garments.user_id FK).

ProductVariant 1–* UserGarment – a variant can be owned by many users (user_garments.variant_id FK) – this is crucial for proxy queries.

UserGarment 1–* UserGarmentFeedback – a logged item can have multiple feedback points (user_garment_feedback.user_garment_id FK).

FeedbackCode 1–* UserGarmentFeedback – one feedback code can be used in many feedback entries (user_garment_feedback.feedback_code_id FK).

UserGarment 1–* UserGarmentPhoto – a log entry can have multiple photos (user_garment_photos.user_garment_id FK).

User (Profile) self-referential in Follows – user_follows.follower_id → users.id and followee_id → users.id.

User 1–* Likes – user can like many items; each like points to one content (e.g. user_garment_likes.user_id and user_garment_id).

These relationships enforce consistency (e.g., you cannot insert a fit feedback without a valid user_garment, and cannot have a user_garment for a non-existent product, etc.), while also enabling efficient joins for queries (we can join user_garments -> product_variants -> products -> brands to get full context of an item a user tried).

In summary, this modernized schema provides a solid foundation for the fashion-fit app’s logging, size prediction, and social sharing features. It improves upon the two legacy designs by combining their strengths: a robust product catalogue with normalized attributes, a flexible measurement system for cross-brand size computations, and a comprehensive user fit logging with standardized feedback codes and media support. With proper indexing, it will scale to millions of users and items, and it remains extensible for new features like outfits and social networking without major refactoring.